# @package _global_

defaults:
  - override /data:  ids_data
  - override /model: gpt

project: 'TrackAttention'
experiment: 'track_attention' #'TreconLM_pretrained_ids110_reproducibility' 


data:
  artifact_name: test_dataset_seed34721_gl110_bs1500_ds50000
  ground_truth_length: 110
  block_size: 1500
  batch_size: 10  # Reduced for memory safety with majority voting (10 permutations -> effective_batch_size=3)
  test_seed: 34721
  observation_size: 10
  lower_bound_obs_size: 2
  test_dataset_size: 50000


model:
  checkpoint_path: /workspaces/TReconLM/models/models--mli-lab--TReconLM/snapshots/950d152df4daab579e7ef6e65cfb6566b9c392a9/model_seq_len_110.pt
  sampling:
    temperature: 1.0
    top_k: None
    strategy: greedy      # greedy or beam_search, if beam_search, set beam_width below
    #beam_width: 6
    max_new_tokens: ${data.ground_truth_length}
    constrained_generation: False # to just generate ACTG
    # Sequence output parameters
    #save_sequences: false  # Set to true to save GT and predictions for failure analysis
    # Attention tracking parameters
    track_attention: true       # Enable attention weight tracking
    track_all_layers: true      # If true, save attention from ALL layers (high memory usage); if false, only save last layer
    save_per_head_attention: true  # If true, save per-head attention [tokens, heads, seq]; if false, save averaged [tokens, seq] (smaller files)
    attention_output_dir: "<your.data.path>/TReconLM/attention_results/synthetic_L110/all_layers" # Relative - creates under current working directory
    max_samples: 500 # randomly samples max_samples examples from the full artifact using a fixed seed
    permute_traces: false  # If true, randomly permute the order of traces/reads before inference to test for positional bias
    # Majority voting ensemble parameters
    majority_voting:
      enabled: false           # Set to false to disable
      max_permutations: 10    # Number of permutations per example
      seed: 42                # For reproducibility
      tie_breaking_strategy: "first_prediction"  # "random" or "first_prediction" - how to break ties in voting
      test_mode: false         # TEST MODE: Process only test_num_batches batches for quick validation
      test_num_batches: 4     # Number of batches to process in test mode (4 batches = 800 examples with batch_size=200)


  #profile_logit_margin:
  #  enabled: true
  #  num_samples: 1000
