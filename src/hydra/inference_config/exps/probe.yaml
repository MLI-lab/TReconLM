# @package _global_

defaults:
  - override /data:  ids_data
  - override /model: gpt

project: 'Probe'
experiment: 'test' 

data: 
  artifact_name: CPRED_seed34721_gl110_bs1500_ds50000
  ground_truth_length: 110 
  block_size: 1500
  batch_size: 50 
  test_seed: 34721
  observation_size: 10
  lower_bound_obs_size: 2
  test_dataset_size: 50000


model: 
  checkpoint_path: <your.storage.path>/model_checkpoints/Substitutions/ids_data_nuc_CPRED_obs10_gt110_compute_subs_only/subs_only/train_run_gpt_20250921_161108/checkpoint_best.pt
  sampling:
    temperature: 1.0
    top_k: None
    strategy: greedy      # greedy or beam_search, if beam_search, set beam_width below
    #beam_width: 6
    max_new_tokens: ${data.ground_truth_length}
    constrained_generation: False # to just generate ACTG 
    return_hidden_states: true
    return_logits: false

probe:
  checkpoint_path: <your.storage.path> # path checkpoints should be saved to for linear probe
  enabled: true
  results_dir: outputs/probe_counts # Relative - creates under current working directory
  test_frac: 0.2
  seed: 100
  lr: 1e-3
  weight_decay: 1e-4
  epochs: 10
  batch_size_tokens: 65536    # positions per batch (not clusters)
  append_logN: true
  layer: -1                   # last layer (reserved if you later expose multiple)
  use_mse_loss: true       # if false, uses CrossEntropyLoss
